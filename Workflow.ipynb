{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-copying",
   "metadata": {},
   "source": [
    "# Workflow Control\n",
    "This notebook provides an end-to-end procedure for implementing the method described in \"Unsupervised Deep Clustering of Seismic Data: Monitoring the Ross Ice Shelf, Antarctica.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-dating",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "***\n",
    "## Table of Contents\n",
    "\n",
    "1. [Initialize Project Environment](#section1)\n",
    "2. [Seismic Pre-Processing](#section2)\n",
    "3. [Set Universal Experiment Parameters](#section3)\n",
    "4. [Pre-train DEC Model](#section4)\n",
    "4. [Train DEC Model](#section5)\n",
    "5. [Cluster Entire Dataset](#section6)\n",
    "\n",
    "Appendices  \n",
    "A. [Evaluate Optimal Number of Clusters](#appendixA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "\n",
    "from RISCluster import models, plotting, utils\n",
    "from RISCluster.networks import AEC, DEC\n",
    "from RISProcess.io import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-writer",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "***\n",
    "## 1 Initialize Project Environment\n",
    "The default project structure is:<br>\n",
    "`/Project Folder\n",
    "├── Config\n",
    "├── Data\n",
    "│   ├── Meteo\n",
    "│   ├── Ice\n",
    "│   ├── Seismo\n",
    "│   │   ├── MSEED\n",
    "│   │   └── StationXML\n",
    "└── Outputs\n",
    "`\n",
    "<br>Note that the raw seismic data from 1-Dec-2014 to 1-Dec-2016 is nearly 1 TB. It may be practical to split out the project's `Data` folder onto a disk with more storage.  If so, set the path to the data storage below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main project folder to save outputs:\n",
    "project_folder = '.'\n",
    "# Path to configuration files:\n",
    "path_config = f\"{project_folder}/Config\"\n",
    "# Path to folder containing data, including HDF file for ML workflow:\n",
    "path_data = f\"{project_folder}/Data\"\n",
    "# Path to raw seismic data:\n",
    "path_data_seismo = f\"{path_data}/Seismo\"\n",
    "# Path to save workflow outputs (ML models, figures, results, etc.)\n",
    "path_output = f\"{project_folder}/Outputs\"\n",
    "# Path to HDF dataset:\n",
    "fname_dataset = f\"{path_data}/RISData.h5\"\n",
    "# Path to save paper-ready figures:\n",
    "figure_savepath = f\"{path_output}/Figures\"\n",
    "\n",
    "utils.init_project_env([path_config, path_data, path_data_seismo, path_output, figure_savepath])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-accident",
   "metadata": {},
   "source": [
    "<a href=\"#contents\">Return to Top</a>\n",
    "<a id=\"section2\"></a>\n",
    "***\n",
    "## 2 Seismic Pre-Processing\n",
    "Four workflows are provided for obtaining and pre-processing seismic data.  The recommended workflow makes use of sections 2.1, 2.3, and 2.4; section 2.2 is not required for the rest of the workflow, but instead provides a pipeline to save pre-processed data to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-vanilla",
   "metadata": {},
   "source": [
    "### 2.1 Download Data\n",
    "In this workflow, seismic data is downloaded using the FDSN mass data downloader. Data set parameters are stored in the configuration file to configpath; MSEED data are saved to `datapath/MSEED`; and station XML data are saved to `datapath/StationXML`.  The MSEED data are saved according to the following convention:\n",
    "`Network.Station..Channel__YYYYMMDDTHHMMSSZ__YYYYMMDDTHHMMSSZ.mseed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'start': '20141201T0000',\n",
    "    'stop': '20141203T0000',\n",
    "    'mode': 'download',\n",
    "    'datapath': path_data_seismo,\n",
    "    'network': 'XH',\n",
    "    'station': '*',\n",
    "    'channel': 'HH*',\n",
    "}\n",
    "config_file = config('w', path=path_config, parameters=parameters)\n",
    "print(\"Run the following in Terminal:\")\n",
    "md(f\"`dlfdsn {config_file}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-electricity",
   "metadata": {},
   "source": [
    "### 2.2 Pre-process Data\n",
    "In this workflow, raw seismic data is read from `datapath`, processed, and saved to `writepath` according to the following file naming conventions:<br>\n",
    "`MSEED/Network/Station/Network.Station.Channel.YYYY.DAY.mseed`\n",
    "\n",
    "For the input data, two file formats are available.\n",
    "<br>**Format 1:**\n",
    "<br>`Network.Station.Channel.YYYY.DAY.mseed`\n",
    "<br>**Format 2:**\n",
    "<br>`Network.Station..Channel__YYYYMMDDTHHMMSSZ__YYYYMMDDTHHMMSSZ.mseed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'start': '20141201T0000',\n",
    "    'stop': '20141203T0000',\n",
    "    'mode': 'preprocess',\n",
    "    'sourcepath': path_data_seismo,\n",
    "    'name_format': 2,\n",
    "    'writepath': f\"{path_data_seismo}/Preprocessed\",\n",
    "    'parampath': f\"{path_data_seismo}/Preprocessed\",\n",
    "    'network': 'XH',\n",
    "    'channel': 'HHZ',\n",
    "    'taper': 60,\n",
    "    'prefeed': 60,\n",
    "    'fs2': 50,\n",
    "    'cutoff': '3, 20',\n",
    "    'output': 'acc',\n",
    "    'prefilt': '0.004, 0.01, 500, 1000',\n",
    "    'waterlevel': 14,\n",
    "    'detector': 'z',\n",
    "    'on': 8,\n",
    "    'off': 4,\n",
    "    'num_workers': 4\n",
    "}\n",
    "config_file = config('w', path=path_config, parameters=parameters)\n",
    "print(\"Run the following in Terminal:\")\n",
    "md(f\"`process {config_file}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-silly",
   "metadata": {},
   "source": [
    "### 2.3 Detect Events & Build Catalogue\n",
    "In this workflow, raw seismic data in `datapath` are processed in 24-hour segments, and an event detection algorithm is applied. The results of the event detector are compiled into a catalogue that is saved to disk at `writepath`. This catalogue serves as a useful pointer for follow-on processing of events of interest, rather than continuous data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-balloon",
   "metadata": {},
   "source": [
    "#### 2.3.1 Build Unsorted Catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'start': '20141201T0000',\n",
    "    'stop': '20141203T0000',\n",
    "    'mode': 'detect',\n",
    "    'sourcepath': path_data_seismo,\n",
    "    'name_format': 2,\n",
    "    'writepath': path_data,\n",
    "    'parampath': path_data,\n",
    "    'network': 'XH',\n",
    "    'channel': 'HHZ',\n",
    "    'taper': 60,\n",
    "    'prefeed': 60,\n",
    "    'fs2': 50,\n",
    "    'cutoff': '3, 20',\n",
    "    'output': 'acc',\n",
    "    'prefilt': '0.004, 0.01, 500, 1000',\n",
    "    'waterlevel': 14,\n",
    "    'detector': 'z',\n",
    "    'on': 8,\n",
    "    'off': 4,\n",
    "    'num_workers': 4\n",
    "}\n",
    "config_file = config('w', path=path_config, parameters=parameters)\n",
    "print(\"Run the following in Terminal:\")\n",
    "md(f\"`process {config_file}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-criminal",
   "metadata": {},
   "source": [
    "#### 2.3.2 Clean Catalogue\n",
    "Remove duplicate detections, and if desired, detections that occur within a window (s) following an initial detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10\n",
    "!cleancat {path_data + '/catalogue.csv'} --dest {path_data + '/catalogue2.csv'} --window $window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-trout",
   "metadata": {},
   "source": [
    "### 2.4 Build HDF Database from Catalogue\n",
    "In this workflow, a catalogue of detections at catalogue is used to process raw seismic data in `datapath`. In addition to pre-processing, the traces, spectrograms, and metadata of the detections are saved to an HDF database located at `writepath`. Because this workflow is implemented in parallel and results are returned asynchronously, a new catalogue is saved to `writepath.csv` that corresponds to the indexing within the HDF dataset. The index within `writepath.csv` corresponds to the original catalogue at catalogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'start': '20141201T0000',\n",
    "    'stop': '20141203T0000',\n",
    "    'mode': 'cat2h5',\n",
    "    'sourcepath': path_data_seismo,\n",
    "    'name_format': 2,\n",
    "    'writepath': fname_dataset,\n",
    "    'catalogue': f\"{path_data}/catalogue2.csv\",\n",
    "    'parampath': path_data,\n",
    "    'network': 'XH',\n",
    "    'channel': 'HHZ',\n",
    "    'taper': 10,\n",
    "    'prefeed': 10,\n",
    "    'fs2': 50,\n",
    "    'cutoff': '3, 20',\n",
    "    'T_seg': 4,\n",
    "    'NFFT': 256,\n",
    "    'tpersnap': 0.4,\n",
    "    'overlap': 0.9,\n",
    "    'output': 'acc',\n",
    "    'prefilt': '0.004, 0.01, 500, 1000',\n",
    "    'waterlevel': 14,\n",
    "    'detector': 'z',\n",
    "    'on': 8,\n",
    "    'off': 4,\n",
    "    'det_window': 5,\n",
    "    'num_workers': 2\n",
    "}\n",
    "config_file = config('w', path=path_config, parameters=parameters)\n",
    "print(\"Run the following in Terminal:\")\n",
    "md(f\"`process {config_file}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-scholar",
   "metadata": {},
   "source": [
    "<a href=\"#contents\">Return to Top</a>\n",
    "<a id=\"section3\"></a>\n",
    "***\n",
    "## 3 Set Universal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"FullArray\"\n",
    "\n",
    "# Get the number of samples in the dataset.\n",
    "!query_H5size $fname_dataset\n",
    "\n",
    "# Image Sample Indexes for Example Waveforms:\n",
    "img_index = [403049, 334383, 300610, 381290]\n",
    "\n",
    "# Generate new sample index for data set?\n",
    "genflag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "if genflag:\n",
    "    M = 125000\n",
    "    !GenerateSampleIndex $M $fname_dataset $path_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "universal = {\n",
    "    'exp_name': exp_name,\n",
    "    'fname_dataset': fname_dataset,\n",
    "    'savepath': f'./Outputs',\n",
    "    'indexpath': './Data/TraValIndex_M=125000.pkl',\n",
    "    'configpath': './Config'\n",
    "}\n",
    "device = utils.set_device(0)\n",
    "transform = 'sample_norm_cent'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-interpretation",
   "metadata": {},
   "source": [
    "<a href=\"#contents\">Return to Top</a>\n",
    "<a id=\"section4\"></a>\n",
    "***\n",
    "## 4 Pre-train DEC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-handle",
   "metadata": {},
   "source": [
    "### 4.1 Autoencoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_display = AEC().to(device)\n",
    "summary(model_display, (1, 87, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-dayton",
   "metadata": {},
   "source": [
    "### 4.2 Configure Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'mode': 'pretrain',\n",
    "    'n_epochs': 500,\n",
    "    'show': False,\n",
    "    'send_message': True,\n",
    "    'early_stopping': True,\n",
    "    'patience': 10,\n",
    "    'transform': 'sample_norm_cent',\n",
    "    'img_index': str(img_index)[1:-1],\n",
    "    'km_metrics': False,\n",
    "    'klist': '2, 20',\n",
    "    'tb': True,\n",
    "    'tbport': 6999,\n",
    "    'workers': 16\n",
    "}\n",
    "hyperparameters = {\n",
    "    'batch_size': '512, 1024, 2048',\n",
    "    'lr': '0.001, 0.01, 0.1'\n",
    "}\n",
    "init_path = utils.config_training(universal, parameters, hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-penguin",
   "metadata": {},
   "source": [
    "### 4.3 View Detection Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotting.view_detections(fname_dataset, img_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{figure_savepath}/DetectionExamples.eps\", dpi=300, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-active",
   "metadata": {},
   "source": [
    "### 4.4 Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-turkey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Run the following in Terminal:\")\n",
    "md(f\"`runDEC {init_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-agency",
   "metadata": {},
   "source": [
    "<a id=\"BestAEC\"></a>\n",
    "### 4.5 Select Best Autoencoder Run\n",
    "Use Tensorboard to view outputs from the various hyperparameter runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "LR = 0.001\n",
    "\n",
    "expserial = 'Exp20201220T072755'\n",
    "runserial = f'Run_BatchSz={batch_size}_LR={LR}'\n",
    "exp_path = f\"{path_output}/Models/AEC/{expserial}/{runserial}\"\n",
    "\n",
    "AEC_weights = f\"{exp_path}/AEC_Params_Final.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-elimination",
   "metadata": {},
   "source": [
    "Return to [Section 5.2](#ConfigDCM)<br>\n",
    "Return to [Section 7](#section5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-leather",
   "metadata": {},
   "source": [
    "### 4.6 Evaluate Autoencoder Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-horror",
   "metadata": {},
   "source": [
    "#### 4.6.1 Load Data and Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.H5SeismicDataset(\n",
    "    fname_dataset,\n",
    "    transform=transforms.Compose(\n",
    "        [utils.SpecgramShaper(), utils.SpecgramToTensor()]\n",
    "    )\n",
    ")\n",
    "display_subset = Subset(dataset, img_index)\n",
    "\n",
    "model = AEC().to(device)\n",
    "model = utils.load_weights(model, AEC_weights, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-count",
   "metadata": {},
   "source": [
    "#### 4.6.2 Training and Validation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-hanging",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plotting.view_history_AEC(f\"{exp_path}/AEC_history.csv\", show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-seattle",
   "metadata": {},
   "source": [
    "#### 4.6.3 Input, Latent Space, and Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotting.compare_images(\n",
    "    model,\n",
    "    0,\n",
    "    [img_index[0]],\n",
    "    fname_dataset,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2218f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{figure_savepath}/CompareInOut.eps\", dpi=300, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-maine",
   "metadata": {},
   "source": [
    "[Return to Top](#contents)\n",
    "<a id=\"section5\"></a>\n",
    "***\n",
    "## 5. Train DEC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-houston",
   "metadata": {},
   "source": [
    "### 5.1 DEC Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_display = DEC(n_clusters=5).to(device)\n",
    "summary(model_display, (1, 87, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-tactics",
   "metadata": {},
   "source": [
    "<a id=\"ConfigDCM\"></a>\n",
    "### 5.2 Configure Training\n",
    "Run [4.5](#BestAEC) first to get AEC weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'mode': 'train',\n",
    "    'n_epochs': 400,\n",
    "    'update_interval': -1,\n",
    "    'show': False,\n",
    "    'send_message': True,\n",
    "    'saved_weights': AEC_weights,\n",
    "    'transform': 'sample_norm_cent',\n",
    "    'tb': True,\n",
    "    'tbport': 6999,\n",
    "    'workers': 16,\n",
    "    'init': 'gmm'\n",
    "}\n",
    "hyperparameters = {\n",
    "    'n_clusters': '8',\n",
    "    'batch_size': '1024',\n",
    "    'lr': '0.001',\n",
    "    'gamma': '0.1',\n",
    "    'tol': 0.002\n",
    "}\n",
    "init_path = utils.config_training(universal, parameters, hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-burner",
   "metadata": {},
   "source": [
    "### 5.3 Train DEC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-division",
   "metadata": {},
   "source": [
    "Run the following in Terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f\"`runDEC {init_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-poverty",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "To specify which CUDA device(s) is(are) used, prepend the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f\"`CUDA_VISIBLE_DEVICES=#`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-syria",
   "metadata": {},
   "source": [
    "<a id=\"BestDEC\"></a>\n",
    "### 5.4 Select Best DEC Run\n",
    "Use Tensorboard to view outputs from the various hyperparameter runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 8\n",
    "batch_size = 1024\n",
    "LR = 0.001\n",
    "\n",
    "expserial = 'Exp20201226T120534'\n",
    "runserial = f'Run_Clusters={n_clusters}_BatchSz={batch_size}_LR={LR}_gamma=0.05_tol=0.002'\n",
    "exp_path = f\"{path_output}/Models/DEC/{expserial}/{runserial}\"\n",
    "DEC_weights = f\"{exp_path}/DEC_Params_Final.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-factory",
   "metadata": {},
   "source": [
    "Return to [Section 6](#section6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-recognition",
   "metadata": {},
   "source": [
    "### 5.5 Evaluate DEC Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-retrieval",
   "metadata": {},
   "source": [
    "#### 5.5.1 Load Data and Model Parameters\n",
    "\n",
    "In this step, two models are instantiated: one before clustering, and one after clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-heather",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = utils.H5SeismicDataset(\n",
    "    fname_dataset,\n",
    "    transform=transforms.Compose(\n",
    "        [utils.SpecgramShaper(), utils.SpecgramToTensor()]\n",
    "    )\n",
    ")\n",
    "index_tra, _ = utils.load_TraVal_index(fname_dataset, universal['indexpath'])\n",
    "tra_dataset = Subset(dataset, index_tra)\n",
    "dataloader = DataLoader(tra_dataset, batch_size=1024, num_workers=16)\n",
    "\n",
    "DEC_weights1 = f\"{exp_path}/DEC_Params_Initial.pt\"\n",
    "DEC_weights2 = DEC_weights\n",
    "\n",
    "model1 = DEC(n_clusters).to(device)\n",
    "model1 = utils.load_weights(model1, DEC_weights1, device)\n",
    "model2 = DEC(n_clusters).to(device)\n",
    "model2 = utils.load_weights(model2, DEC_weights2, device)\n",
    "\n",
    "centroids1 = model1.clustering.weights.detach().cpu().numpy()\n",
    "centroids2 = model2.clustering.weights.detach().cpu().numpy()\n",
    "\n",
    "_, labels1, data1 = models.infer(dataloader, model1, device, v=True)\n",
    "_, labels2, data2 = models.infer(dataloader, model2, device, v=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-submission",
   "metadata": {},
   "source": [
    "#### 5.5.2 Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = view_history_DEC([f\"{exp_path}/DEC_history.csv\", f\"{exp_path}/Delta_history.csv\"], show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-diversity",
   "metadata": {},
   "source": [
    "#### 5.5.3 Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "fig = plotting.cluster_gallery(\n",
    "    model2,\n",
    "    dataloader.dataset,\n",
    "    fname_dataset,\n",
    "    index_tra,\n",
    "    device,\n",
    "    data2,\n",
    "    labels2,\n",
    "    centroids2,\n",
    "    p,\n",
    "    True,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{figure_savepath}/gallery.eps\", dpi=300, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-harrison",
   "metadata": {},
   "source": [
    "#### 5.5.4 t-SNE Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == 'darwin':\n",
    "    from sklearn.manifold import TSNE\n",
    "elif sys.platform == 'linux':\n",
    "    from cuml import TSNE\n",
    "\n",
    "M = len(data1)\n",
    "results1 = TSNE(n_components=2, perplexity=int(M/50), early_exaggeration=2000, learning_rate=int(M/25), n_iter=3000, verbose=0, random_state=2009).fit_transform(data1.astype('float64'))\n",
    "results2 = TSNE(n_components=2, perplexity=int(M/50), early_exaggeration=2000, learning_rate=int(M/25), n_iter=3000, verbose=0, random_state=2009).fit_transform(data2.astype('float64'))\n",
    "fig1 = plotting.view_TSNE(results1, labels1, 't-SNE Results: GMM', True)\n",
    "fig2 = plotting.view_TSNE(results2, labels2, 't-SNE Results: DEC', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = view_TSNE(results1, labels1, 't-SNE Results: GMM', show=True)\n",
    "fig2 = view_TSNE(results2, labels2, 't-SNE Results: DEC', show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1.savefig(f\"{figure_savepath}/tSNE_i.pdf\", dpi=300, facecolor='w')\n",
    "fig2.savefig(f\"{figure_savepath}/tSNE_f.pdf\", dpi=300, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-recipe",
   "metadata": {},
   "source": [
    "#### 5.5.5 DEC Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "fig = plotting.centroid_dashboard(\n",
    "    data2,\n",
    "    labels2,\n",
    "    centroids2,\n",
    "    n_clusters,\n",
    "    p,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-inspection",
   "metadata": {},
   "source": [
    "#### 5.5.6 View Centroid Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "fig = plotting.centroid_distances(\n",
    "    data2,\n",
    "    labels2,\n",
    "    centroids2,\n",
    "    n_clusters,\n",
    "    p,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-collection",
   "metadata": {},
   "source": [
    "#### 5.5.7 View Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "fig = plotting.view_latent_space(\n",
    "    data1,\n",
    "    data2,\n",
    "    labels1,\n",
    "    labels2,\n",
    "    centroids1,\n",
    "    centroids2,\n",
    "    n_clusters,\n",
    "    p,\n",
    "    True,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{figure_savepath}/zspace.pdf\", dpi=300, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-wrist",
   "metadata": {},
   "source": [
    "#### 5.5.8 Cluster CDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "fig = plotting.view_class_cdf(\n",
    "    data1,\n",
    "    data2,\n",
    "    labels1,\n",
    "    labels2,\n",
    "    centroids1,\n",
    "    centroids2,\n",
    "    n_clusters,\n",
    "    p,\n",
    "    True,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{figure_savepath}/CDF.pdf\", dpi=300, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-genetics",
   "metadata": {},
   "source": [
    "#### 5.5.9 Cluster PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 2\n",
    "fig = plotting.view_class_pdf(\n",
    "    data1,\n",
    "    data2,\n",
    "    labels1,\n",
    "    labels2,\n",
    "    centroids1,\n",
    "    centroids2,\n",
    "    n_clusters,\n",
    "    p,\n",
    "    True,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{figure_savepath}/PDF.pdf\", dpi=300, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-attraction",
   "metadata": {},
   "source": [
    "[Return to Top](#contents)\n",
    "<a id=\"section6\"></a>\n",
    "***\n",
    "## 6 Cluster Entire Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-warning",
   "metadata": {},
   "source": [
    "### 6.1 Configure Inference\n",
    "Run [Section 5.4](#BestDEC) first to get DEC weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'mode': 'predict',\n",
    "    'send_message': False,\n",
    "    'saved_weights': DEC_weights,\n",
    "    'transform': 'sample_norm_cent',\n",
    "    'workers': 16,\n",
    "    'tb': False\n",
    "}\n",
    "init_path = utils.config_training(universal, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-charlotte",
   "metadata": {},
   "source": [
    "### 6.2 Run DEC Model in Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Run the following in Terminal:\")\n",
    "md(f\"`runDEC {init_path}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-powell",
   "metadata": {},
   "source": [
    "### 6.3 Calculate Dataset Statistics\n",
    "Set path to clustering results and data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_catalogue = f\"{fname_dataset}.csv\"\n",
    "path_to_labels = f\"{exp_path}/Labels.csv\"\n",
    "catalogue = utils.LabelCatalogue([path_to_catalogue, path_to_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a78d4",
   "metadata": {},
   "source": [
    "#### 6.3.1 Station Statistics\n",
    "View occurrence frequencies by station and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue.station_statistics().sort_values(by=\"N\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a21e2f",
   "metadata": {},
   "source": [
    "#### 6.3.2 Amplitude Statistics\n",
    "View amplitude characteristics for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adf79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue.amplitude_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef80390b",
   "metadata": {},
   "source": [
    "#### 6.3.3 Seasonal Statistics\n",
    "Compare occurrence frequencies in austral winter (JFM) to austral summer (JJA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e7e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue.seasonal_statistics(mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c486aa",
   "metadata": {},
   "source": [
    "#### 6.3.4 Peak Frequency Statistics\n",
    "View average peak frequencies for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09abf433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catalogue.get_peak_freq(fname_dataset, batch_size=2048, workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f774971",
   "metadata": {},
   "source": [
    "### 6.4 View Environmental Data & Detection Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe662dc",
   "metadata": {},
   "source": [
    "#### 6.4.1 View Station DR02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531629b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = \"DR02\"\n",
    "aws = \"gil\"\n",
    "fig = plotting.view_series(\n",
    "    station,\n",
    "    aws,\n",
    "    path_data,\n",
    "    path_to_catalogue,\n",
    "    path_to_labels,\n",
    "    env_vars=[\"sea_ice_conc\",\"temp\",\"wind_spd\"],\n",
    "    freq=\"hour\",\n",
    "    maxcounts=20,\n",
    "    title=f\"Station {station} Inter-annual Scale\",\n",
    "    show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(f\"{figure_savepath}/{station}.eps\", dpi=300, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634a845",
   "metadata": {},
   "source": [
    "#### 6.4.2 View Station RS09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = \"RS09\"\n",
    "aws = \"mgt\"\n",
    "start = datetime.datetime(2016,6,15)\n",
    "stop = datetime.datetime(2016,7,15)\n",
    "fig1 = plotting.view_series(\n",
    "    station,\n",
    "    aws,\n",
    "    path_data,\n",
    "    path_to_catalogue,\n",
    "    path_to_labels,\n",
    "    env_vars=[\"temp\",\"wind_spd\",\"tide\"],\n",
    "    vlines=[start, stop],\n",
    "    freq=\"hour\",\n",
    "    maxcounts=30,\n",
    "    figsize=(12,9),\n",
    "    title=f\"Station {station} Interannual Scale\",\n",
    "    show=True\n",
    ")\n",
    "fig2 = plotting.view_series(\n",
    "    station,\n",
    "    aws,\n",
    "    path_data,\n",
    "    path_to_catalogue,\n",
    "    path_to_labels,\n",
    "    env_vars=[\"temp\",\"wind_spd\",\"tide\"],\n",
    "    times=[start, stop],\n",
    "    freq=\"hour\",\n",
    "    maxcounts=20,\n",
    "    figsize=(6,9),\n",
    "    title=f\"Station {station} Weekly Scale\",\n",
    "    showlabels=False,\n",
    "    show=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1.savefig(f\"{figure_savepath}/{station}_ia.eps\", dpi=300, facecolor='w')\n",
    "fig2.savefig(f\"{figure_savepath}/{station}_wk.eps\", dpi=300, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cfa56c",
   "metadata": {},
   "source": [
    "<a href=\"#contents\">Return to Top</a>\n",
    "<a id=\"appendixA\"></a>\n",
    "***\n",
    "## Appendix A: Test for Optimal Number of Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bbf6bc",
   "metadata": {},
   "source": [
    "### A.1 Load Data\n",
    "Run <a href=\"#BestAEC\">4.5</a> first to get AEC weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_tra, _ = utils.load_TraVal_index(fname_dataset, universal['indexpath'])\n",
    "\n",
    "tra_dataset = Subset(dataset, index_tra)\n",
    "dataloader = DataLoader(tra_dataset, batch_size=512, num_workers=16)\n",
    "\n",
    "model = AEC().to(device)\n",
    "model = utils.load_weights(model, AEC_weights, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d2693",
   "metadata": {},
   "source": [
    "### A.2 Compute K-means Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f063967",
   "metadata": {},
   "outputs": [],
   "source": [
    "klist = '2, 20'\n",
    "klist = np.arange(int(klist.split(',')[0]), int(klist.split(',')[1])+1)\n",
    "inertia, silh, gap_g, gap_u = models.kmeans_metrics(dataloader, model, device, klist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219404ea",
   "metadata": {},
   "source": [
    "### A.3 Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotting.view_cluster_stats(klist, inertia, silh, gap_g, gap_u, show=True)\n",
    "np.save('kmeans_inertia', inertia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RISCluster_CUDA",
   "language": "python",
   "name": "riscluster_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
